# 30. Substring with Concatenation of All Words

## Index

- [30. Substring with Concatenation of All Words](#30-substring-with-concatenation-of-all-words)
  - [Index](#index)
  - [Problem](#problem)
    - [Link](#link)
    - [Description and Examlpe](#description-and-examlpe)
    - [Relation](#relation)
  - [Solution1: fixed window](#solution1-fixed-window)
    - [Idea](#idea)
    - [Complexity](#complexity)
    - [Code](#code)
  - [Solution2: elastic window](#solution2-elastic-window)
    - [Idea](#idea-1)
    - [Complexity](#complexity-1)
    - [Code](#code-1)

----

## Problem

### Link

- [30. Substring with Concatenation of All Words][1]

### Description and Examlpe

You are given a string, `s`, and a list of words, `words`, that are **all of the same length**. Find all starting indices of substring(s) in `s` that is a concatenation of each word in `words` **exactly once** and without any intervening characters.

note: 虽然 `words` 中的每个词只能用一次, 但是 `words` 中可能有重复的词, 例如 example2

Example 1

```nohighlight
Input:
    s = "barfoothefoobarman",
    words = ["foo","bar"]
Output: [0.9]
```

Example 2:

```nohighlight
Input:
    s = "wordgoodgoodgoodbestword",
    words = ["word","good","best","word"]
Output: []
```

### Relation

- [Topic: Two Pointers][2]

----

## Solution1: fixed window

### Idea

用一个定长窗口对 s 上 slen - wcnt * wlen 个可能的起始位置进行检测, 用 hash 表记录窗口内出现的单词. 非常直觉的算法...没啥好说的.

### Complexity

- Time: `O(wcnt):Build target hashmap + O(slen * wcnt):Match = O(slen * wcnt)`
- Space: `O(wcnt)`

### Code

```java
class Solution {
    public List<Integer> findSubstring(String s, String[] words) {
        List<Integer> ans = new ArrayList<>();
        if (s == null || words == null || words.length < 1) {
            return ans;
        }
        int slen = s.length();
        int wcnt = words.length;
        int wlen = words[0].length();
        Map<String, Integer> h = new HashMap<>();
        for (String word : words) {
            h.put(word, h.getOrDefault(word, 0) + 1);
        }

        for (int i = 0; i <= slen - wcnt * wlen; i++) {
            Map<String, Integer> tmp = new HashMap<>();
            int j = 0;
            while (j < wcnt) {
                String sub = s.substring(i+j*wlen, i+(j+1)*wlen);
                if (h.containsKey(sub)) {
                    tmp.put(sub, tmp.getOrDefault(sub, 0) + 1);
                    if (tmp.get(sub) > h.get(sub)) break;
                } else {
                    break;
                }
                j++;
            }
            if (j == wcnt) ans.add(i);
        }

        return ans;
    }
}
```

----

## Solution2: elastic window

### Idea

[Solution1](#solution1-fixed-window) 中用一个定长窗口对 s 上 slen - wcnt * wlen 个可能的起始位置进行检测, 但是仔细想想这种方法还有很大优化空间. 试想下面这种情况:

> 一个定长窗口匹配了绝大部分 words, 只差两个 word, 这两个 words 就在这个窗口右侧; 而差这两个 words 的原因是这个窗口最左端的两个 words 不匹配.

这种情况下我们要再等两个循环才能找到这个解. 相当于我们**完全舍弃了部分匹配信息**. 并且由于 java 中 `String.substring()` 方法的时间复杂度是 `O(N)` 而非 `O(1)` (不过分析时间复杂度的时候还是当作 `O(1)`), 所以舍弃部分匹配信息的代价就比较大了.

为了使用部分匹配信息, 一种自然的想法是: 用一个变长窗口对 s 上 wlen 个可能的起始位置进行检测, 每次都把 s "扫一次", 得到所有解. 这就是 Solution2 的基本思想. 其具体步骤如下:

1. Tokenization. 目的是降低算法耗时. 从两个方面理解, 一方面减少了 `String.substring()` 的调用次数; 另一方面 tokenization 后可以用数组代替 hash 表存储窗口, 这样速度也会快一些.
2. 最后的问题是窗口长度变化的规则, 这里用两个 case 做简单说明.

    ```nohighlight
    [s, e) is the window.

    -------TARGET--------
    tokens: 1   2   3   4
    cnt:    2   1   1   1
    -------TARGET--------

    At the beginning  | After this loop
    of this loop      |
    ------------------|------------------
    3  2  1  1  1  4  | 3  2  1  1  1  4  
    s           e     |          s     e  
    ------------------|------------------
    3  2  1  1 -1  4  | 3  2  1  1 -1  4
    s           e     |               se
    ```

### Complexity

- Time: `O(slen):Tokenization + O(slen/wlen * wlen):Match = O(slen)`
- Space: `O(slen + wcnt)`

### Code

```java
class Solution {
    public List<Integer> findSubstring(String s, String[] words) {
        List<Integer> ans = new ArrayList<>();
        if (s == null || words == null || words.length < 1) {
            return ans;
        }
        int slen = s.length();
        int wcnt = words.length;
        int wlen = words[0].length();

        /* Tokenization
         * word --hash--> tokenID --cnt--> number of this word in words[]
         */
        Map<String, Integer> h = new HashMap<>();
        int[] cnt = new int[wcnt];
        int tokenID = 0;
        for (String word : words) {
            if (!h.containsKey(word)) {
                h.put(word, tokenID);
                cnt[tokenID++] = 1;
            } else {
                cnt[h.get(word)]++;
            }
        }

        int[] smap = new int[slen-wlen+1];
        for (int i = 0; i <= slen - wlen; i++) {
            smap[i] = h.getOrDefault(s.substring(i, i + wlen), -1);
        }

        for (int i = 0; i < wlen; i++) {
            int start = i, end = i;       // [start, end) is the window
            int[] wincnt = new int[wcnt]; // Count the number of each tokenID in the window
            while (end <= slen - wlen) {
                if (smap[end] != -1 && wincnt[smap[end]] < cnt[smap[end]]) {
                    wincnt[smap[end]]++;
                } else {
                    while (start < end && smap[start] != smap[end]) {
                        wincnt[smap[start]]--;
                        start += wlen;
                    }
                    start += wlen;
                }
                end += wlen;
                // Check if we get an answer.
                // Instead of check whether wincnt & cnt are consistent,
                // we just calculate the length of the window.
                if ((end - start) == wlen * wcnt)
                    ans.add(start);
            }
        }

        return ans;
    }
}
```

[1]: https://leetcode.com/problems/substring-with-concatenation-of-all-words/
[2]: ../topics/two-pointers.md
